{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Main notebook taking an input, does the filtering for the location and returns pandas dictionary containing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "\n",
    "import io\n",
    "import os\n",
    "#os.path.join(os.getcwd(),'wave-site-studies','site_data')\n",
    "import pathlib\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./support')\n",
    "sys.path.insert(0,'./site_data/support')\n",
    "\n",
    "from ipynb.fs.defs.Coordinates import Coordinates\n",
    "from ipynb.fs.defs.Sites import wave_columns, Site, File\n",
    "from ipynb.fs.defs.Databases import Database\n",
    "from ipynb.fs.defs.Grid import Grid,Border\n",
    "from ipynb.fs.defs.Periods import Period\n",
    "\n",
    "from ipynb.fs.defs.wave_data_qc import df_monthly_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotebookPATH = './wave-site-studies/site_data/'\n",
    "currPath=pathlib.Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function for scrapping the webpage containing table of stations with their coordinates.\n",
    "\n",
    "For the subset of dataset, see https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork_spectral.subset\n",
    "\n",
    "Since there are different locations belonging to same station, \n",
    "function also takes the mean of every lat,lon value of each station.\n",
    "\n",
    "Two new column added to the dataframe which consist stations' max and min distances to the mean coordinate value.\n",
    "'''\n",
    "def get_Ireland_buoy_list():\n",
    "    \n",
    "    url = 'https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork_spectral.subset'\n",
    "    response = requests.get(url).text\n",
    "        \n",
    "    buoy_list = pd.read_html(str(response),skiprows=[1],header=[0],attrs={\"class\":\"erd commonBGColor nowrap\"})[0]\n",
    "    buoy_list.columns=['Station_ID','Station_Name','Latitude','Longitude']\n",
    "        \n",
    "    #Station Ids are not proper\n",
    "    buoy_list.drop('Station_ID', axis=1, inplace=True) \n",
    "    \n",
    "    #Same buoy exist in different locations. Define a mean value for the locations\n",
    "    #Since a buoy with one unusual coordinate has detected, need to eliminate it. the buoy is Amets Berth A Wave Buoy with latitude 57,...  \n",
    "    old_list = buoy_list.copy()\n",
    "    \n",
    "    #site name will be index with the groupby func..\n",
    "    buoy_list = buoy_list.groupby(['Station_Name']).mean()\n",
    "    \n",
    "    for index,row in old_list.iterrows():\n",
    "        c1 = Coordinates(float(row['Latitude']),float(row['Longitude']))\n",
    "        #mean value\n",
    "        c2 = Coordinates(float(buoy_list.loc[row.Station_Name , 'Latitude']),float(buoy_list.loc[row.Station_Name , 'Longitude']))\n",
    "        distance = c1.distance(c2)\n",
    "        #to eliminate the unusual coordinates\n",
    "        if distance > 200:\n",
    "            old_list.drop([index], inplace=True)\n",
    "\n",
    "    buoy_list = old_list.groupby(['Station_Name']).mean()     \n",
    "    buoy_list.reset_index(inplace=True)\n",
    "    buoy_list['Grid']=Grid('Ireland_MarineInstitute', 'get_Ireland_data', './wave-site-studies/site_data/',Database.Ireland,Period.Tp,None)\n",
    "    buoy_list['Latitude']=buoy_list['Latitude'].astype(float).round(2)\n",
    "    buoy_list['Longitude']=buoy_list['Longitude'].astype(float).round(2) \n",
    "    \n",
    "    return buoy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Ireland_buoy_list_raw():\n",
    "    \n",
    "    url = 'https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork_spectral.subset'\n",
    "    response = requests.get(url).text\n",
    "        \n",
    "    buoy_list = pd.read_html(str(response),skiprows=[1],header=[0],attrs={\"class\":\"erd commonBGColor nowrap\"})[0]        \n",
    "    buoy_list.columns=['Station_ID','Station_Name','Latitude','Longitude']\n",
    "    buoy_list['Grid']=Grid('Ireland_MarineInstitute', 'get_Ireland_data', './wave-site-studies/site_data/',Database.Ireland,Period.Tp,None)\n",
    "    buoy_list['Latitude']=buoy_list['Latitude'].astype(str)\n",
    "    buoy_list['Longitude']=buoy_list['Longitude'].astype(str) \n",
    "    \n",
    "    return buoy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GoMOOS_buoy_list():  \n",
    "    url = 'https://coastwatch.pfeg.noaa.gov/erddap/tabledap/gomoosBuoy.subset'\n",
    "\n",
    "    response = requests.get(url).text\n",
    "    buoy_list = pd.read_html(str(response),skiprows=[1],header=[0],attrs={\"class\":\"erd commonBGColor nowrap\"})[0]\n",
    "    buoy_list.columns=['Station_ID','Longitude','Latitude']\n",
    "    buoy_list['Grid']=Grid('GoMOOS', 'get_Maine_data', './wave-site-studies/site_data/', Database.GoMOOS, Period.Tp, None)\n",
    "    buoy_list['Latitude']=buoy_list['Latitude'].astype(float).round(2)\n",
    "    buoy_list['Longitude']=buoy_list['Longitude'].astype(float).round(2) \n",
    "    buoy_list.drop_duplicates(subset='Station_ID', inplace=True)\n",
    "    buoy_list.reset_index(inplace=True,drop=True)\n",
    "    return buoy_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_GoMOOS_buoy_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CDIP_buoy_list():\n",
    "    #url='http://cdip.ucsd.edu/themes/cdip?pb=1&d2=p2&tz=UTC&ll=0&un=0&u2=tab:2:ibf:1:ibc:1'\n",
    "    url='http://cdip.ucsd.edu/themes/cdip?pb=1&d2=p2&tz=UTC&ll=0&un=0&u2=mode:filter:show:none:tab:2'\n",
    "    response = requests.get(url).text\n",
    "    soup = bs4(response)\n",
    "            \n",
    "    station_table = soup.find(\"table\" , {\"class\":\"tablesorter table\", \"id\":\"myTable_\"})    \n",
    "    station_list = pd.read_html(str(station_table))[0]\n",
    "    station_list.columns=['Station_ID','Station_Name','Data Set Name','Start(UTC)','End(UTC)','Latitude','Longitude','Depth(m)','Funding','Operator']\n",
    "    \n",
    "    #station_list = station_list[station_list['Station Name'].str.contains(', CA',case=False,regex=False)]\n",
    "    station_list = station_list[station_list['Operator'].str.contains('CDIP',case=False,regex=False,na=False)]\n",
    "    station_list['Grid']=Grid('California_CDIP', 'get_CDIP_data', './wave-site-studies/site_data/', Database.CDIP, Period.Tp, None)\n",
    "    \n",
    "    #delete duplicates. There are duplicate records of some stations with the only difference in their datatset name.\n",
    "    station_list.drop(['Data Set Name','Start(UTC)','End(UTC)','Funding','Operator'],axis=1,inplace=True)\n",
    "    \n",
    "    station_list.drop_duplicates(subset='Station_ID', inplace=True)\n",
    "    station_list.reset_index(inplace=True, drop=True)\n",
    "    #station_list['Latitude']=station_list['Latitude'].astype(str)\n",
    "    #station_list['Longitude']=station_list['Longitude'].astype(str)\n",
    "    station_list['Latitude']=station_list['Latitude'].astype(float).round(2)\n",
    "    station_list['Longitude']=station_list['Longitude'].astype(float).round(2)\n",
    "    station_list['Station_ID'] = station_list['Station_ID'].astype(str)\n",
    "    \n",
    "    return station_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_CDIP_buoy_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NDBC_buoy_list():\n",
    "    url='https://sdf.ndbc.noaa.gov/stations.shtml'\n",
    "    response = requests.get(url).text\n",
    "    #buoy_list = pd.read_html(str(response),attrs={\"class\":\"erd commonBGColor nowrap\"})[0]\n",
    "    soup = bs4(response)\n",
    "    \n",
    "    station_table = soup.findAll(\"table\")    \n",
    "    station_list = pd.read_html(str(station_table))[8]\n",
    "    #column names to protect from any update \n",
    "    station_list.columns=['Station_ID','Station_Name','Owner','Latitude','Longitude','Sensor']\n",
    "                            \n",
    "    #filtering the result list\n",
    "    #station_list = station_list[station_list['Owner'].str.contains('NDBC',case=False,regex=False)]\n",
    "    station_list = station_list[station_list['Sensor'].str.contains('Waves',case=False,regex=False)]\n",
    "    station_list.drop(['Sensor','Owner'],axis=1,inplace=True)\n",
    "\n",
    "    station_list['Grid']=Grid('NDBC', 'get_NDBC_data', './wave-site-studies/site_data/', Database.NDBC, Period.Tp, None)\n",
    "    station_list['Latitude']=station_list['Latitude'].astype(float).round(2)\n",
    "    station_list['Longitude']=station_list['Longitude'].astype(float).round(2) \n",
    "    station_list.drop_duplicates(subset='Station_ID', inplace=True)\n",
    "    station_list.reset_index(inplace=True, drop=True)\n",
    "    #Ndbc has int value stations ids not string.. \n",
    "    station_list['Station_ID'] = station_list['Station_ID'].astype(str)\n",
    "    \n",
    "    return station_list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get_platforms_erddap('VHM0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import xml.etree.ElementTree as et \n",
    "\n",
    "def get_platforms_erddap(param):\n",
    "    \n",
    "    dbID = 'EP_ERD_INT_%s_AL_TS_NRT.subset?EP_PLATFORM_ID,EP_PLATFORM_CODE,EP_PLATFORM_TYPE&.viewDistinctData=10000&.viewRelatedData=0&distinct()'\n",
    "    url='https://erddap.emodnet-physics.eu/erddap/tabledap/'+dbID % param\n",
    "    response = requests.get(url, verify=False).text\n",
    "\n",
    "    platforms = pd.read_html(str(response),skiprows=[1],header=[0],attrs={\"class\":\"erd commonBGColor nowrap\"})[0]\n",
    "    platforms.columns=['Station_ID','Station_Name','Platform_Type']\n",
    "    platforms['Station_ID']=platforms['Station_ID'].astype(str)\n",
    "    platforms.drop_duplicates(subset='Station_ID', inplace=True)\n",
    "    platforms.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return platforms\n",
    "\n",
    "def get_emodnet_buoy_list():\n",
    "#buoy list is saved in a file and loaded from there. The file gets an update every two months. \n",
    "#This is because an Emodnet API needs to be called to get lat,lon values. \n",
    "#And doing that for every station takes time like 5 mins.\n",
    "#File name is the date it got its' last update.\n",
    "    allErddapStations = pd.DataFrame()\n",
    "    \n",
    "    if os.path.split(os.getcwd())[1] == 'site_data':path='./'\n",
    "    else:path='./site_data/'\n",
    "    path += './data/buoy_list/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file = glob.glob(path + 'Emodnet_platforms_*.csv')\n",
    "    \n",
    "    if len(file):\n",
    "        file=file[0]\n",
    "        #name of the file has a format. The date comes after '_' before '.csv' :\n",
    "        dateofUpdate = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "        dateofUpdate = datetime.strptime(dateofUpdate, '%Y%m%d')\n",
    "        two_months = date.today() + relativedelta(months=-2)\n",
    "        dateofUpdate = datetime.date(dateofUpdate)\n",
    "\n",
    "        if two_months <= dateofUpdate:\n",
    "            #print('getting platforms from a file')\n",
    "            allErddapStations = pd.read_csv(file)\n",
    "            allErddapStations.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "    if allErddapStations.empty:\n",
    "        print('emodnet platforms list needs to be updated. This might take time around 5 mins. getting platforms from emodnet erddap ...')\n",
    "        \n",
    "        #Since vhm0 is the only height that will be used for now, only common ids in periods list are included and used.\n",
    "        #Data without period won't be useful.\n",
    "        #Order of the variable list is important. It's based on priority. Eg. VTPK should be used as the principal period var. \n",
    "        #So drop duplicates will take the first ones and delete the last existings.  \n",
    "        varlist=['VTPK','VTZA','VTM02','VTM10']\n",
    "        vhm0 = get_platforms_erddap('VHM0')\n",
    "        common=pd.DataFrame()\n",
    "\n",
    "        for var in varlist:\n",
    "            platforms=get_platforms_erddap(var)\n",
    "            allErddapStations = allErddapStations.append(platforms, ignore_index=True)\n",
    "\n",
    "        allErddapStations.drop('Platform_Type', axis=1, inplace=True)\n",
    "        allErddapStations.drop_duplicates(subset='Station_ID', inplace=True)\n",
    "        allErddapStations.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        for i,r in allErddapStations.iterrows():\n",
    "            if (vhm0['Station_ID'] == (r['Station_ID'])).any():\n",
    "                url= 'https://www.emodnet-physics.eu/Map/service/WSEmodnet2.aspx?q=GetPlatformId&PlatformID=%s' % str(r['Station_ID'])\n",
    "                response = requests.get(url).text\n",
    "                xml_root = et.fromstring(response)\n",
    "                platform = xml_root.findall('Platform') \n",
    "                if platform:\n",
    "                    r['Latitude'] = platform[0].find('Latitude').text\n",
    "                    r['Longitude'] = platform[0].find('Longitude').text\n",
    "                    r['LastDataMeasured'] = platform[0].find('LastDataMeasured').text\n",
    "                    params= platform[0].find('Parameters').text\n",
    "                    params = list(params.split(';'))\n",
    "                    if 'VTPK' in params: r['Ttype'] = 'Tp'\n",
    "                    elif 'VTM10' in params: r['Ttype'] = 'Te'\n",
    "                    else: r['Ttype'] = 'Tz'\n",
    "                        \n",
    "                    common=common.append(r)\n",
    "                    \n",
    "        allErddapStations=common\n",
    "        allErddapStations.reset_index(inplace=True, drop=True)\n",
    "        file = 'Emodnet_platforms_%s.csv' % date.today().strftime('%Y%m%d')\n",
    "        allErddapStations.to_csv(path + file, index=False)\n",
    "        \n",
    "    #allErddapStations['Grid']=Grid('EMODnet_Physics', 'get_Emodnet_data', './wave-site-studies/site_data/', Database.Emodnet, None, None)\n",
    "    grid_all = pd.Series()\n",
    "    for i,r in allErddapStations.iterrows():\n",
    "        #allErddapStations.iloc[i].Grid.Ttype = Period(r['Ttype'])\n",
    "        grid_all = grid_all.append(pd.Series(Grid('EMODnet_Physics', 'get_Emodnet_data', './wave-site-studies/site_data/', Database.Emodnet, Period(r['Ttype']), None), index =[allErddapStations.index[i]]))\n",
    "    allErddapStations['Grid'] = grid_all        \n",
    "    \n",
    "    allErddapStations.drop('Ttype', axis=1, inplace=True)\n",
    "    allErddapStations['Station_ID'] = allErddapStations['Station_ID'].astype(str)\n",
    "    allErddapStations['Latitude']= allErddapStations['Latitude'].astype(str).str.replace(',','.', regex=False).astype(float).round(2)\n",
    "    allErddapStations['Longitude']= allErddapStations['Longitude'].astype(str).str.replace(',','.', regex=False).astype(float).round(2)\n",
    "    \n",
    "    return allErddapStations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "get_emodnet_buoy_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buoy_network():\n",
    "    df1 = get_Ireland_buoy_list()\n",
    "    df2 = get_GoMOOS_buoy_list()\n",
    "    df3 = get_CDIP_buoy_list()\n",
    "    df4 = get_NDBC_buoy_list()\n",
    "    df5 = get_emodnet_buoy_list()\n",
    "    \n",
    "    buoy_network = pd.concat([df1,df2,df4,df3,df5], axis=0, ignore_index=True, sort=False)\n",
    "    #buoy_network = pd.concat([df1,df2,df3,df4,df5], axis=0, sort=False, keys=['ireland','gomoos','cdip','ndbc','emodnet'])\n",
    "    \n",
    "    #Those which has missing of either station name or id, will be assigned the same value as the other attribute.\n",
    "    buoy_network['Station_ID'] = buoy_network['Station_ID'].fillna(buoy_network['Station_Name'])\n",
    "    buoy_network['Station_Name'] = buoy_network['Station_Name'].fillna(buoy_network['Station_ID'])\n",
    "    \n",
    "    #buoy_network.drop_duplicates(subset='Station_ID',inplace=True)\n",
    "    #buoy_network['Station_ID'] = buoy_network['Station_ID'].astype(str)\n",
    "    \n",
    "    return buoy_network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = get_buoy_network()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buoy_data(sites, time_start, time_end, swell=False, max_distance=200):\n",
    "    \n",
    "    Data = {}\n",
    "    stations = pd.DataFrame()\n",
    "    start_year = int(time_start[0:4])\n",
    "    end_year = int(time_end[0:4])\n",
    "    #since this nb may be running from other directories..\n",
    "    #find the root directory\n",
    "    \n",
    "    #J_ROOT = os.readlink('/proc/%s/cwd' % os.environ['JPY_PARENT_PID'])\n",
    "    #current directory\n",
    "    #curr_path=os.getcwd()\n",
    "    #change dir\n",
    "    #os.chdir(J_ROOT)\n",
    "    #os.chdir(NotebookPATH)\n",
    "    #now we can directly use grid.name\n",
    "    \n",
    "    #and at the end change dir back to the old one\n",
    "    \n",
    "    #Above solution did not work for all systems. Root is the starting point of jupyter notebook and can differ from terminal.\n",
    "    #Current solution is path split written below\n",
    "    path = os.path.split(pathlib.Path().absolute())\n",
    "    path_tail = path[1]\n",
    "    \n",
    "    if path_tail == 'wave-site-studies':\n",
    "        os.chdir('./site_data')\n",
    "        \n",
    "    elif path_tail != 'site_data':\n",
    "        print('The path is not accurate, please change it')\n",
    "        \n",
    "    buoy_network = get_buoy_network()\n",
    "    buoy_network['distance'] = None\n",
    "    \n",
    "    for site in sites: \n",
    "        min_dist=max_distance\n",
    "        buoys=pd.DataFrame()\n",
    "        closest_buoy=pd.DataFrame()\n",
    "        selected_buoy=None\n",
    "        site_data=pd.DataFrame()\n",
    "        \n",
    "        if site.file:\n",
    "            notebook = 'Read_from_file.ipynb'\n",
    "            func = site.file.function_name\n",
    "            %run $notebook\n",
    "            site_data, Ttype = globals()[func](site, time_start, time_end)\n",
    "                \n",
    "        if site.force_db:\n",
    "            stations = buoy_network[buoy_network['Grid'].apply(lambda x: x.database == site.force_db)]\n",
    "            #print('stations:')\n",
    "            #display(stations)\n",
    "            #if it returned an empty dataframe, then direct to gridded model data\n",
    "            #if a model data is wanted..\n",
    "            if stations.empty:\n",
    "                print('Getting data from grid system (model data)...')\n",
    "                %run Wave_grid_filter.ipynb\n",
    "                site_data,Ttype = get_model_data(site, time_start, time_end)\n",
    "\n",
    "        if site.force_id:\n",
    "            station = buoy_network[buoy_network['Station_ID']==str(site.force_id)]\n",
    "            #station = buoy_network[buoy_network['Station_ID']==str(site.force_id)]\n",
    "            if not station.empty:\n",
    "                print('force_id station found:')\n",
    "                display(station)\n",
    "                station = station.iloc[0]\n",
    "                #grid=(station.Grid)\n",
    "                notebook = station['Grid'].name+'.ipynb'\n",
    "                func = station['Grid'].function\n",
    "                %run $notebook\n",
    "                #eval(func) #to use eval, add params to string as well. Eval might not be so secure to use...\n",
    "                site_data = globals()[func](time_start,time_end,station.Station_ID)\n",
    "                Ttype=station.Grid.Ttype\n",
    "                if site_data.empty: print('There is no data available at station ' + str(station['Station_Name']))\n",
    "            else: \n",
    "                print('There is no buoy with given ID: ' + str(site.force_id) + ' for the site ' + site.name)\n",
    "                continue\n",
    "        \n",
    "        if site_data.empty:   \n",
    "            if not stations.empty: df_iter = stations\n",
    "            else: df_iter = buoy_network\n",
    "            #for row in (stations.itertuples() if not stations.empty else buoy_network.itertuples()):\n",
    "            for row in df_iter.itertuples():\n",
    "            #find the nearest point to the wanted site\n",
    "                distance = site.coordinates.distance(Coordinates(row.Latitude,row.Longitude))\n",
    "                df_iter.loc[row.Index, 'distance'] = round(distance,2)\n",
    "                #row.distance = distance\n",
    "                #the limit for difference in the distance is set to 3km\n",
    "                if distance < max_distance:\n",
    "                    if distance < 3:\n",
    "                        #print('found new buoy closer than 3 km') \n",
    "                        buoys=buoys.append([row])\n",
    "                        #buoys = buoys.append(row)\n",
    "                    #for the buoys having distances higher than 3 km, trying to have the closest among them..\n",
    "                    elif distance < min_dist:\n",
    "                        min_dist = distance\n",
    "                        #this is to save an extra close buoy in case the most closest ones does not have data\n",
    "                        closest_buoy = row\n",
    "\n",
    "            #if a buoy has found from the dataframe, call the related notebook\n",
    "            #when there are more than one station, then take the first one giving data and show others to the user..\n",
    "            if not buoys.empty:\n",
    "                buoys.reset_index(inplace=True, drop=True)\n",
    "                #data= list()\n",
    "                #gather all buoys data and compare within each other...\n",
    "                data = {}\n",
    "                site_data = pd.DataFrame()             \n",
    "                \n",
    "                for buoy in buoys.itertuples():\n",
    "                    notebook =  buoy.Grid.name+'.ipynb'\n",
    "                    func = buoy.Grid.function\n",
    "                    %run $notebook\n",
    "                    #eval(func) #to use eval, add params to string as well. Eval might not be so secure to use...\n",
    "                    df = globals()[func](time_start,time_end,buoy.Station_ID)\n",
    "\n",
    "                    if not df.empty:\n",
    "                        #data.append(df)\n",
    "                        data[buoy.Station_ID] = df\n",
    "                        if site_data.empty: \n",
    "                            site_data = df\n",
    "                            Ttype=buoy.Grid.Ttype\n",
    "                            closest_buoy=buoy\n",
    "                    #until one of the buoys get some data...\n",
    "                    \n",
    "                if len(buoys) > 1:\n",
    "                    #if there are other buoys having same/similar coordinates, display them to the user, and finish the loop..\n",
    "                    print('For the site ' + site.name + ' there are more than one buoys found for the location.')\n",
    "                    print('All available buoys: ')\n",
    "                    display(buoys)\n",
    "                    if site_data.empty:\n",
    "                        print('None of the buoys provided data')\n",
    "                    else:\n",
    "                        print('Data gathered from: ')\n",
    "                        #display(pd.DataFrame(closest_buoy))\n",
    "                        display(pd.DataFrame([closest_buoy]))\n",
    "                        if len(data) > 1 and (end_year-start_year <= 1):\n",
    "                            print('Monthly comparison of all buoys data:')\n",
    "                            display(df_monthly_comparison(data))\n",
    "                    print('In order to get data from another buoy, add selected buoys station id as a force_id parameter to the corresponding site input.')\n",
    "                \n",
    "            if site_data.empty and not len(closest_buoy)==0:\n",
    "            #that means there is an extra buoy which is the closest after other most close buoys..\n",
    "                notebook = closest_buoy.Grid.name+'.ipynb'\n",
    "                func = closest_buoy.Grid.function\n",
    "                %run $notebook\n",
    "                site_data = globals()[func](time_start,time_end,closest_buoy.Station_ID)\n",
    "                Ttype=closest_buoy.Grid.Ttype\n",
    "\n",
    "            #if there is no data retreived, then look at the regional/global model datasets    \n",
    "            if site_data.empty:\n",
    "                print('Site ', site.name, ' has no data available. No buoy/s provided data. Getting data from a model')\n",
    "                %run Wave_grid_filter.ipynb\n",
    "                site_data,Ttype = get_model_data(site, time_start, time_end) \n",
    "\n",
    "                #path_list=list(buoy.Grid.dir_path.split('/'))\n",
    "                #path_list.append(buoy.Grid.name+'.ipynb')\n",
    "                #path1 = os.path.join(*path_list)\n",
    "\n",
    "                #if buoy['LastDataMeasured']:\n",
    "                #if (int(buoy['LastDataMeasured']) < int(time_start[0:4])):\n",
    "       \n",
    "        if not Data:\n",
    "            Data = {'site names' : [site.name],\n",
    "                'latitudes' : [site.coordinates.latitude],\n",
    "                'longitudes' : [site.coordinates.longitude], \n",
    "                'Hs' : ['Hs(m)_' + site.name],\n",
    "                'T' : [{'name':'Tp(s)_' + site.name , 'type':Ttype}]}\n",
    "            if not len(closest_buoy)==0:\n",
    "                Data.update({'nearest buoys': [{'station id': closest_buoy.Station_ID,\n",
    "                                               'latitude': closest_buoy.Latitude,\n",
    "                                               'longitude': closest_buoy.Longitude,\n",
    "                                               'distance (km)': min_dist}]})\n",
    "            Data.update({'timeSeries' : site_data[time_start : time_end]})\n",
    "            \n",
    "        else:\n",
    "            Data['timeSeries'] = Data['timeSeries'].join(site_data[time_start : time_end] , how='outer' , lsuffix=('_'+Data['site names'][-1]), rsuffix=('_'+site.name))\n",
    "            Data['site names'].append(site.name)\n",
    "            Data['latitudes'].append(site.coordinates.latitude)\n",
    "            Data['longitudes'].append(site.coordinates.longitude)\n",
    "            Data['Hs'].append('Hs(m)_' + site.name)\n",
    "            Data['T'].append({'name':'Tp(s)_' + site.name,'type':Ttype})\n",
    "            if not len(closest_buoy)==0:\n",
    "                if 'nearest buoys' in Data:\n",
    "                    Data['nearest buoys'].append({'station id': closest_buoy.Station_ID,\n",
    "                                                 'latitude': closest_buoy.Latitude,\n",
    "                                                 'longitude': closest_buoy.Longitude,\n",
    "                                                 'distance (km)': min_dist})\n",
    "                else:\n",
    "                    Data.update({'nearest buoys': [{'station id': closest_buoy.Station_ID,\n",
    "                                                   'latitude': closest_buoy.Latitude,\n",
    "                                                   'longitude': closest_buoy.Longitude,\n",
    "                                                   'distance (km)': min_dist}]})\n",
    "    os.chdir(currPath)\n",
    "            \n",
    "    return Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Time interval\n",
    "start = '20110101T00'\n",
    "end = '20111231T23'\n",
    "\n",
    "sites=[Site('San Nicolas Island',Coordinates(33.22,-119.88), force_id=27683)]\n",
    "get_buoy_data(sites,start,end)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#808\n",
    "dropped = [x.drop_duplicates(subset=['Latitude','Longitude'])]\n",
    "\n",
    "dropped"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = x[x.duplicated(subset=['Latitude','Longitude'], keep=False)]        #257\n",
    "#df = x[x.duplicated(subset=['Latitude','Longitude'], keep='first')]     #133\n",
    "#df = x[x.duplicated(subset=['Latitude','Longitude'], keep='last')]      #133\n",
    "\n",
    "#df = x[x.duplicated(subset=['Station_Name'], keep=False)]\n",
    "\n",
    "df=df.sort_values(by=['Latitude'])\n",
    "df\n",
    "\n",
    "\n",
    "#df['Grid'].loc[df['Grid'].apply(lambda x: 'California_CDIP' in (x))]\n",
    "#df.loc[df['Grid'].name=='California_CDIP']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#print (x.dtypes)\n",
    "\n",
    "#df = x[x.duplicated(subset=['Latitude','Longitude'], keep=False)]\n",
    "#df = x[x.duplicated(subset=['Latitude','Longitude'], keep='first')]\n",
    "df = x[x.duplicated(subset=['Latitude','Longitude'], keep='last')]\n",
    "\n",
    "#df = x[x.duplicated(subset=['Station_Name'], keep=False)]\n",
    "\n",
    "df=df.sort_values(by=['Latitude'])\n",
    "#df.to_csv('./data/buoy_list/allPlatforms.csv', index=False)\n",
    "df\n",
    "\n",
    "# sub-list check"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "#3667\t41099\tMO\n",
    "#17361\t4100099\tMO\n",
    "#vtpk:\n",
    "#3667\t41099\tMO\n",
    "\n",
    "'''\n",
    "ravel() is an array method than returns a view (if possible) of a multidimensional array. \n",
    "The argument 'K' tells the method to flatten the array in the order the elements are stored in memory \n",
    "(pandas typically stores underlying arrays in Fortran-contiguous order; columns before rows). \n",
    "This can be significantly faster than using the method's default 'C' order.\n",
    "'''\n",
    "\n",
    "pd.unique(x[['Latitude', 'Longitude']].values.ravel('K'))\n",
    "\n",
    "len(pd.concat([x['Latitude'], x['Longitude']]).unique())   #1408\n",
    "\n",
    "unique = x.groupby(['Latitude', 'Longitude']).size().reset_index(name='Freq')\n",
    "#unique.to_csv('./data/buoy_list/allPlatforms_unique.csv', index=False)\n",
    "#print (x['Latitude'] == unique['Latitude'])\n",
    "print(unique)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x['Station_ID']=x['Station_ID'].astype(str)\n",
    "\n",
    "x['Station_ID'].describe()\n",
    "\n",
    "#x.loc[x['Grid'].apply(lambda x: x.name=='NDBC')]\n",
    "\n",
    "#x.loc[x.Station_ID == '46014']\n",
    "\n",
    "#x['Latitude'] = x['Latitude'].round(2)\n",
    "\n",
    "#unique buoys\n",
    "#same lat.lon\n",
    "#priority\n",
    "#distance differ 20m\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start='20170506'\n",
    "end='20181231'\n",
    "# \n",
    "s = Site('X' , Coordinates(53.23 , -100.27))\n",
    "s2 = Site('Belmullet' , Coordinates(54.23 , -10.14))\n",
    "sites = [s,s2]\n",
    "get_buoy_data(sites, start, end, Database.WaveWatch3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start='20170506'\n",
    "end='20181231'\n",
    "# \n",
    "s = Site('X' , Coordinates(53.23 , -9.27))\n",
    "s2 = Site('Belmullet' , Coordinates(54.23 , -10.14))\n",
    "sites = [s,s2]\n",
    "get_buoy_data(sites, start, end, Database.Ireland)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#Time interval\n",
    "start = '20110101T00'\n",
    "end = '20111231T23'\n",
    "\n",
    "sites=[Site('San Nicolas Island',Coordinates(33.22,-119.88)),\n",
    "       Site('Cape Mendocino',Coordinates(40.29,-124.73)),\n",
    "       Site('Belmullet',Coordinates(54.13,10.13)),\n",
    "       Site('Galway',Coordinates(53.23, -9.27)),\n",
    "       Site('Harpswell',Coordinates(43.76,-69.99)),\n",
    "       Site('WESTERN HAWAII (Adrift)',Coordinates(19.289,-160.569)),\n",
    "       Site('Maili',Coordinates(21.41,-158.18))]\n",
    "\n",
    "get_buoy_data(sites,start,end)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Time interval\n",
    "start = '20110101T00'\n",
    "end = '20111231T23'\n",
    "\n",
    "sites=[Site('San Nicolas Island',Coordinates(33.22,-119.88)),\n",
    "       Site('Cape Mendocino',Coordinates(40.29,-124.73)),\n",
    "       Site('Belmullet',Coordinates(54.13,10.13)),\n",
    "       Site('Galway',Coordinates(53.23, -9.27)),\n",
    "       Site('Harpswell',Coordinates(43.76,-69.99)),\n",
    "       Site('WESTERN HAWAII (Adrift)',Coordinates(19.289,-160.569)),\n",
    "       Site('Maili',Coordinates(21.41,-158.18))]\n",
    "\n",
    "get_buoy_data(sites,start,end)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Time interval\n",
    "start = '20110101T00'\n",
    "end = '20111231T23'\n",
    "\n",
    "sites=[Site('San Nicolas Island',Coordinates(33.22,-119.88), force_db=Database.Emodnet)]\n",
    "get_buoy_data(sites,start,end)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Time interval\n",
    "start = '20110101T00'\n",
    "end = '20111231T23'\n",
    "\n",
    "sites=[Site('San Nicolas Island',Coordinates(33.22,-119.88)),\n",
    "       Site('Cape Mendocino',Coordinates(40.29,-124.73)),\n",
    "       Site('Belmullet',Coordinates(54.13,10.13)),\n",
    "       Site('Galway',Coordinates(53.23, -9.27)),\n",
    "       Site('Harpswell',Coordinates(43.76,-69.99)),\n",
    "       Site('WESTERN HAWAII (Adrift)',Coordinates(19.289,-160.569)),\n",
    "       Site('Maili',Coordinates(21.41,-158.18))]\n",
    "\n",
    "get_buoy_data(sites,start,end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
