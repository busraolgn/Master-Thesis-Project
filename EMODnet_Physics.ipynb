{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "from urllib.parse import quote \n",
    "import urllib\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'./support')\n",
    "\n",
    "from ipynb.fs.defs.Coordinates import Coordinates\n",
    "from ipynb.fs.defs.Sites import wave_columns, Site\n",
    "from ipynb.fs.defs.Periods import Period\n",
    "from ipynb.fs.defs.time_index import convert_index, stitch, remove_duplicate_inputs, clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "import urllib3\n",
    "http = urllib3.PoolManager(\n",
    "    cert_reqs='CERT_REQUIRED',\n",
    "    ca_certs=certifi.where())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Erddap Data Server\n",
    "For data access form, see 'https://erddap.marine.ie/erddap/tabledap/IWaveBNetwork_spectral.html'\n",
    "'''\n",
    "db_name = 'EP_ERD_INT_%s_AL_TS_NRT.csv'\n",
    "\n",
    "#important variable order. Period will be Tp if available. If not, Te will be the type. Lastly Tz...\n",
    "varlist=['VTPK','VTM10','VTZA','VTM02']\n",
    "param_max_vals={'VHM0' : 50, 'VTPK' : 30, 'VTM10' : 30, 'VTZA' : 30, 'VTM02' : 30}\n",
    "#height cannot be higher than 50m and period cannot be higher than 30s..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_platforms_erddap(param):\n",
    "    \n",
    "    dbID = 'EP_ERD_INT_%s_AL_TS_NRT.subset?EP_PLATFORM_ID,EP_PLATFORM_CODE,EP_PLATFORM_TYPE&.viewDistinctData=10000&.viewRelatedData=0&distinct()'\n",
    "    \n",
    "    url='https://erddap.emodnet-physics.eu/erddap/tabledap/'+dbID % param\n",
    "    response = requests.get(url, verify=False).text\n",
    "\n",
    "    platforms = pd.read_html(str(response),skiprows=[1],header=[0],attrs={\"class\":\"erd commonBGColor nowrap\"})[0]\n",
    "    platforms.drop_duplicates(subset='EP_PLATFORM_ID', inplace=True)\n",
    "    platforms.columns=['PlatformID','PlatformName','PlatformType']\n",
    "    platforms['PlatformID']=platforms['PlatformID'].astype(str)\n",
    "    platforms.reset_index(inplace=True, drop=True)\n",
    "    return platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, param):\n",
    "    df = df[df[param].map(format).astype('float') < param_max_vals[param]]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df1,df2):\n",
    "    if len(df1)==0:return df2\n",
    "    if len(df2)==0:return df1\n",
    "    f1=df1.index.freq\n",
    "    f2=df2.index.freq\n",
    "    if f1!=f2:\n",
    "        print('These 2 dataframe do not have the same frequency and cannot be stitched together!',f1,f2)\n",
    "        print(df2)\n",
    "        if(len(df1)>len(df2)):return df1\n",
    "        else:return df2\n",
    "    tz1=df1.index.tz\n",
    "    tz2=df2.index.tz\n",
    "    if tz1!=tz2:#Sometimes tz are defined as pytz or pandas.tz\n",
    "        df2.index=df2.index.tz_convert(tz1)\n",
    "    if (df2.index[0] - df1.index[-1]) < f1:\n",
    "        return df1.append(df2)\n",
    "    #some stitching is required to fill the gap between df1 and df2\n",
    "    newindex = pd.date_range(start=df1.index[0],end=df2.index[-1],freq=f1,tz=df1.index.tz)\n",
    "    newindex.freq=f1\n",
    "    newindex.name=df1.index.name\n",
    "    if isinstance(df1, pd.DataFrame):\n",
    "        df=pd.DataFrame(index=newindex,columns=df1.columns)\n",
    "    else:\n",
    "        df=pd.Series(index=newindex,name=df1.name)\n",
    "    df.loc[df1.index]=df1\n",
    "    df.loc[df2.index]=df2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A function that returns wave data belonging to a specific year and a station taken as parameters.\n",
    "If the data is not saved in the system, fetches it from ERDDAP server via request URL.\n",
    "'''\n",
    "\n",
    "def get_year_data(station_id, year, variable):\n",
    "    \n",
    "    filename = str(station_id)+'_'+str(year)+'_'+db_name % variable\n",
    "    path = 'data/EMODnet/'\n",
    "    \n",
    "    if os.path.split(os.getcwd())[1] == 'site_data':here='./'\n",
    "    else:here='./site_data/'\n",
    "    \n",
    "    path = here + path\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    filename = path + filename\n",
    "    if os.path.isfile(filename):\n",
    "        wave_data = pd.read_csv(filename)\n",
    "      \n",
    "    else:\n",
    "        url = 'https://erddap.emodnet-physics.eu/erddap/tabledap/'+db_name % variable+'?'\n",
    "        variables = 'EP_PLATFORM_ID,EP_PLATFORM_CODE,time,depth,latitude,longitude,%s,area' % variable        \n",
    "        time_start = str(year) + '-01-01T00:00:00Z'\n",
    "        time_end = str(year) + '-12-31T23:59:00Z'\n",
    "        url_add = variables\n",
    "        url_add += '&EP_PLATFORM_ID=\"' + str(station_id) + '\"' \n",
    "        url_add += '&time>=' + time_start\n",
    "        url_add += '&time<=' + time_end\n",
    "\n",
    "        #encode query in order to assure correct url format\n",
    "        url += urllib.parse.quote(url_add , safe='=&-')\n",
    "        #print(url)\n",
    "        response = requests.get(url, verify=False)\n",
    "        \n",
    "        #If no data has queued (possibly due to no data at a given date etc.)\n",
    "        #code 200 = ok\n",
    "        if response.status_code != 200 : \n",
    "            print('station ' + str(station_id) + ' data not available at given times')\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        response = response.content\n",
    "        #first row of the data is reserved for variable units \n",
    "        wave_data = pd.read_csv(io.StringIO(response.decode('utf-8')) , sep = ',' , header=0, skiprows=[1])\n",
    "        #print(wave_data)\n",
    "        if not wave_data.empty:\n",
    "            wave_data.columns = ['station_id','station_name','time (UTC)','depth','latitude','longitude',variable,'area']             \n",
    "            wave_data.drop(['station_id','station_name','depth','latitude','longitude','area'], axis=1, inplace=True)\n",
    "            \n",
    "            #eliminate unusual values\n",
    "            wave_data = remove_outliers(wave_data, variable)\n",
    "            #wave_data[variable] = wave_data[variable].round(2)\n",
    "            wave_data.to_csv(filename, index=False)\n",
    "    return wave_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Main function that takes user inputs as parameter \n",
    "and returns dictionary structure containing Ireland data with the desired stations and the time frame.\n",
    "\n",
    "Inputs are; a site object(site_name, *coordinates), start time, end time\n",
    "\n",
    "Station id is assigned according to the given coordinates. \n",
    "If that coordinate is not in Ireland stations list, then the closest one within distance limit is calculated and assigned. \n",
    "\n",
    "Current distance limit is 200 km.\n",
    "'''\n",
    "def get_Emodnet_data(time_start, time_end, station_id, swell=False):\n",
    "    print('Getting data from Emodnet')\n",
    "    if swell:\n",
    "        print('Station ' + station_id + ' has no swell data available')\n",
    "    \n",
    "    start_year = int(time_start[0:4])\n",
    "    end_year = int(time_end[0:4])\n",
    "    years = list(range(start_year, end_year+1))        \n",
    "    site_data=pd.DataFrame()\n",
    "    \n",
    "    #height and period has separate databases. \n",
    "    #only height variable is vhm0 but period differs.\n",
    "    #find the parameter that station belongs to...\n",
    "    for var in varlist:\n",
    "        platforms= get_platforms_erddap(var)\n",
    "        if (platforms['PlatformID'] == str(station_id)).any():\n",
    "            param=var\n",
    "            for y in years: \n",
    "                height_data = get_year_data(station_id , y, 'VHM0')\n",
    "                #if no data returned, go next year\n",
    "                if height_data.empty: continue\n",
    "                period_data = get_year_data(station_id , y, param)\n",
    "                if period_data.empty: continue\n",
    "               \n",
    "                if not height_data.index.equals(period_data.index): \n",
    "                    print('two parameter indexes are not matching')\n",
    "                    display(height_data.index, period_data.index)\n",
    "                #site_data = site_data.join(period_data, how='inner', lsuffix=('Hs'), rsuffix=('T'))\n",
    "                #site_data = pd.concat([site_data,period_data], axis=1)\n",
    "                #mergedDf = site_data.merge(period_data, left_index=True, right_index=True)\n",
    "                height_data[param] = period_data[param]\n",
    "                if site_data.empty: site_data = clean_data(height_data, station_id)[time_start:time_end]\n",
    "                else: site_data = stitch(site_data , clean_data(height_data, station_id)[time_start:time_end])\n",
    "            if not site_data.empty: \n",
    "                site_data.columns= ['Hs(m)_Emodnet(vhm0)_'+str(station_id), 'T(s)_Emodnet('+param+')_'+str(station_id)]\n",
    "            break           \n",
    "        \n",
    "    return site_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = '20100101'\n",
    "end = '20101231'\n",
    "\n",
    "get_Emodnet_data(start,end,27683)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = '20150101'\n",
    "end = '20151231'\n",
    "get_Emodnet_data(start,end,739905)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start = '20110101'\n",
    "end = '20110301'\n",
    "get_Emodnet_data(start,end,27683)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "height=get_platforms_WaveHeight()\n",
    "#tp=get_platforms_Tp()\n",
    "\n",
    "s1 = pd.merge(height, station_list, how='inner', on=['PlatformID'])\n",
    "#print(s1)\n",
    "common_count=0\n",
    "diff_count=0\n",
    "dif_list=list()\n",
    "param_count=0\n",
    "for i,r in station_list.iterrows():\n",
    "    if 'VHM0' in row['Parameters'].values[0]:\n",
    "        row=height.loc[height['PlatformID'] == r['PlatformID']]\n",
    "        if row is None:\n",
    "            print(r)\n",
    "    \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        diff_count+=1\n",
    "        dif_list.append(r)\n",
    "print('For vtdh; common points '+str(common_count)+' different points '+str(diff_count)+ ' paramcount '+str(param_count))\n",
    "print(dif_list)\n",
    "\n",
    "for i,r in height.iterrows():\n",
    "    if r['PlatformID'] in station_list['PlatformID'].values:\n",
    "        common_count+=1\n",
    "        row = station_list.loc[station_list['PlatformID'] == r['PlatformID']]\n",
    "        if 'VHM0' in row['Parameters'].values[0]:\n",
    "            param_count+=1\n",
    "        \n",
    "    else:\n",
    "        diff_count+=1\n",
    "        dif_list.append(r)\n",
    "print('For vtdh; common points '+str(common_count)+' different points '+str(diff_count)+ ' paramcount '+str(param_count))\n",
    "print(dif_list)\n",
    "\n",
    "\n",
    "s1 = pd.merge(height, station_list, how='inner', on=['PlatformID'])\n",
    "print(s1)\n",
    "common_count=0\n",
    "diff_count=0\n",
    "dif_list=list()\n",
    "for i,r in height.iterrows():\n",
    "    if r['PlatformID'] in station_list['PlatformID'].values:\n",
    "        common_count+=1\n",
    "    else:\n",
    "        diff_count+=1\n",
    "        dif_list.append(r)\n",
    "print('For height; common points '+str(common_count)+' different points '+str(diff_count))\n",
    "print(dif_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
